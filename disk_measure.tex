\documentclass[10pt,a4paper]{article}
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}

%\usepackage[showframe]{geometry}

\usepackage[
backend=bibtex,
sorting=ynt
]{biblatex}
\addbibresource{refs.bib}

\defbibheading{secbib}[\bibname]{%
	\section*{#1}%
	\markboth{#1}{#1}}

\usepackage{graphicx}
\usepackage{subfig}
\usepackage{todonotes}
\usepackage{amsfonts}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{amsthm}
\usepackage{tabularx}
\usepackage{array}
\setlength\extrarowheight{2pt} % or whatever amount is appropriate
\usepackage{hyperref}
\usepackage[capitalise, noabbrev]{cleveref}
\usepackage{float}
\usepackage{mathbbol}
%\usepackage{tikz-cd}
\usepackage{tikz}
\usepackage{enumitem}
\usepackage{xcolor}
\usepackage{tcolorbox}
\tcbuselibrary{breakable}

\usepackage{newpxtext,newpxmath} % Should be the last package import

\theoremstyle{definition}
\newtheorem{thm}{Theorem}[section]
\newtheorem{defn}[thm]{Definition}
\newtheorem{lem}{Lemma}[thm]
\newtheorem{cor}{Corollary}[thm]
\newtheorem{prop}{Proposition}[thm]
\newtheorem{rem}{Remark}[thm]
\newtheorem{ill}{Illustration}[thm]
\newtheorem{ex}{Example}[thm]

\newcommand{\conv}[1]{\ensuremath{\operatorname{conv}(#1)}}
\newcommand{\posreals}{\ensuremath{\mathbb{R}_{>0}}}
\newcommand{\R}{\mathbb{R}}
\newcommand{\pers}{\mathcal{D}}

\newenvironment{idea}{%
	\begin{tcolorbox}[colback=green, breakable, sharp corners]
		\textbf{Idea: }
		\medskip
		\begin{quote}
			\centering
		}{\end{quote}\medskip\end{tcolorbox}}


\setlength\parindent{0pt}

\linespread{1.5}

\title{Draft: Distance to the measure induced by a uniform kernel density estimator.}
\begin{document}
	\maketitle
	
	\todo[inline]{Big question: do we gain anything compared to just using the empirical measure?}
	
	\section{Introduction}
	\subsection{Background}
	\begin{enumerate}
		\item In \autocite{chazal2011geometric}, the authors introduce the distance to a measure. Better stability (Wasserstein stability) guarantees with respect to noise and outliers than the classical stability results for distance functions.
		
		\item In \autocite{Buchet2013} the authors propose an approximation scheme for approximating the sublevel sets of the distance to a measure function using power distances and weighted Čech (and Rips) complexes.
		
		\item They use this approximation scheme to compute the sublevel set homology of the distance to the empirical measure.
		
		\item A similar approach using weighted complexes and power distances have been used in \autocite{Phillips2013} for approximating the sublevel set homology of the kernel distance to a measure.
	\end{enumerate}

	\subsection{Goal}
	\begin{enumerate}
		\item We want to study kernel density estimators using the disk kernel which can be viewed as a thickening of the Dirac measure.
		\item We then consider the measure induced by this KDE and the distance to this measure.
		\item Letting the kernel bandwidth approach zero as the number of samples in the input point cloud grows, we want to show that this gives uniformly stable approximations of the sublevel sets of the distance to measure function.
		\item We may also relate the disk KDE to the multicover bifiltration (\autocite{Blumberg2020}, \autocite{corbet2021}, \autocite{sheehy2012multicover} and \autocite{edelsbrunner2021multi}).
	\end{enumerate}

	\section{Background}
	\subsection{Kernel density estimators}
	We consider the \textit{disk kernel} $D_h\colon\R^d\times\R^d\to\R_{\geq0}$ with \textit{bandwidth parameter} $h\R_{>0}$ defined by
	$$
	(x,y)\mapsto 
	\begin{cases} 
		1 & \Vert x - y\Vert \leq h\text{ and} \\
		0 & \text{otherwise.}
	\end{cases}
	$$
	We then define the \textit{normalized disk kernel} $K_h\colon\R^d\times\R^d\to\R_{\geq0}$ by normalizing the disk kernel such $K_h(x,-)\colon\R^d\to\R_{\geq0}$ integrates to $1$ for all $x\in\R^d$. In other words, $K_h$ is defined as $K_h(x,y):=\frac{\Gamma(\frac{d}{2}+1)}{(h\sqrt{\pi})^d}D_h(x,y)$. Now, given a point cloud $X\subset\R^d$ with $|X|=n$, we define the \textit{disk kernel density estimator (DKDE) $f_{X,h}$ with bandwidth $h$} on $X$ as the weighted sum
	$$
	f_{X,h} = \frac{1}{n}\sum_{x\in X}K_h(x,-)\colon\R^d\to\R_{\geq0}.
	$$
	The induced \textit{disk measure on $X$} is then defined as the probability measure $\mu_{X,h}\colon A\to\int_A f_{X,h}(y)dy$. In other words, for a measurable set $A\subset\R^d$, we have
	$$
	\mu_{X,h}(A) = \frac{\Gamma(\frac{d}{2}+1)}{n(h\sqrt{\pi})^d}\sum_{x\in X}\operatorname{Vol}(A\cap\bar{B}(x,h)).
	$$
	Given any strictly monotonically function $\alpha\colon\mathbb{Z}_{>0}\to\R_{>0}$, we introduce the notation $\mu_{X,\alpha} = \mu_{X,\alpha(n)}$. Put differently, the bandwidth decrease as the number of samples in $X$ increase. For example, we could choose $\alpha(n)=\frac{c}{n}$ for some constant $c\in\R_{>0}$.
	
	\subsection{Distance to a measure}
	Given a probability measure $\mu$ on a metric space $(M,d_M)$ and a mass parameter $m\in(0,1]$, define the \textit{distance to the measure $\mu$}, denoted $d_{\mu,m}\colon M\to\R_{\geq0}$, as
	$$
	d_{\mu,m}(y) = \sqrt{\frac{1}{m}\int_0^m\delta_{\mu, t}^2(y)dt}
	$$
	where $\delta_{\mu,t}\colon M\to\R_{\geq0}$ is defined as $\delta_{\mu,t}(y)=\inf\{r\geq0\mid\mu(\bar{B}(y,r))>t\}$ and $\bar{B}(y,r)=\{m\in M\mid d_M(y,m)\leq r\}$ is the closed ball centred at $y$ of radius $r$.
	
	\begin{ex}
	The distance to the disk measure $d_{X,\alpha, m} := d_{\mu_{X,\alpha}, m}$ is then given by
	$$
	d_{X,\alpha, m}^2(y) = \frac{C(n,d)}{m}\int_0^m\inf\left\{r\geq 0\,\middle\vert\,\sum_{x\in X}\operatorname{Vol}(\bar{B}(y,r)\cap\bar{B}(x,\alpha(n)))\geq t\right\}^2 dt
	$$
	where $C(n,d)=\frac{\Gamma(\frac{d}{2}+1)}{n(\alpha(n)\sqrt{\pi})^d}$.
	\end{ex}

	One of the most important properties of the distance to a measure function is the stability it enjoys with respect to the Wasserstein distance.
	\begin{thm}[Theorem 3.1~and~3.3~in~\autocite{Buchet2013}]
		Let $\mu$ and $\nu$ be probability measures on a metric space $M$ and let $m\in(0,1]$ be a mass parameter. Then,
		$$
		\Vert d_{\mu,m} - d_{\nu,m}\Vert_\infty\leq\frac{1}{\sqrt{m}}W_2(\mu, \nu).
		$$
		Moreover, if $M$ is triangulable, then $\operatorname{Dgm}(d_{\mu, m})$ and $\operatorname{Dgm}(d_{\nu, m})$ are well-defined and
		$$
		d_B(\operatorname{Dgm}(d_{\mu, m}), \operatorname{Dgm}(d_{\nu, m}))\leq\frac{1}{\sqrt{m}}W_2(\mu,\nu).
		$$
	\end{thm}

	\subsubsection{Wasserstein stability for the disk measure}
	Given a point cloud $X\subset\R^d$, we already know an upper bound on the Wasserstein distance $W_p(\mu_X, \mu_{X_0})$ between the empirical measures $\mu_X$ and $\mu_{X_0}$. Now, if we can find an upper bound on the distance $W_2(\mu_{X,\alpha}, \mu_X)$ between the disk measure and the empirical measure on $X$, then we can use the triangle inequality to obtain a bound on $W_2(\mu_{X,\alpha}, \mu_{X_0,\alpha})$. This will help us establish uniform stability for the distance to the disk measure.
	
	\todo[inline]{Find a transport plan (coupling) between $\mu_X$ and $\mu_{X,\alpha}$ providing an upper bound on $W_2$!}


	\subsubsection{Approximating the sublevel sets of $d_{\mu,m}$}
 	Following the exposition given in \autocite{Buchet2013}, we see how the sublevel sets of $d_{\mu,m}$ can be approximated by the union of balls centred at each point in some sample $P$ of $\operatorname{Supp}(\mu)$. Given a subset $P$ of a metric space $(M, d_M)$ and a weight function $w\colon P\to\R$, we define the \textit{power distance} $p(x)\colon M\to\R_{\geq0}$ associated with $(P,w)$ by letting
 	$$
 	p(x)=\sqrt{\min_{p\in P}\left(d_M(x,p)^2+w(p)^2\right)}.
 	$$
 	Let $\mu$ be a probability measure on a metric space $M$ and let $m\in(0,1]$. Given a subset $P\subseteq M$, define $d_{\mu,m}^P$ to be the power distance associated with $(P,d_{\mu,m})$. That is, $d_{\mu,m}^P=\sqrt{\min_{p\in P}\left(d_M(x,p)^2+d_{\mu,m}(p)^2\right)}$
 	\begin{thm}[Theorem~4.5~in~\autocite{Buchet2013}]
 		\label{thm_power_distance_dtm_inequality}
 		If $d_H(P,\operatorname{Supp}(\mu))\leq\epsilon$, then $$\frac{1}{\sqrt{2}}d_{\mu,m}\leq d_{\mu,m}^P \leq \sqrt{5}(d_{\mu,m}+\epsilon).$$
 	\end{thm}
 	For the empirical measure $\mu_X = \frac{1}{|X|}\sum_{x\in X}\delta_x$ on some point cloud $X$ one can choose $P=X$ (giving $\epsilon=0$ in \cref{thm_power_distance_dtm_inequality}) to obtain interleaving guarantees on the sublevel set filtrations of $d_{\mu_X,m}$ and $d_{\mu_X,m}^P$. In the case where $M=\R^d$ with the $L_2$-norm and $\mu$ is the empirical measure $\mu_X$ on $X$, the bounds can be slightly improved to $\frac{1}{\sqrt{2}}d_{\mu,m}\leq d_{\mu,m}^P \leq \sqrt{3}d_{\mu,m}$.

	\begin{ex}
		Consider the distance $d_{X,\alpha, m}$ to the the disk measure $\mu_{X,\alpha}$ on $X$ with $|X|=n$. Then, $P=X$ is an $\alpha(n)$-sample of $\operatorname{Supp}(\mu_{X,\alpha})$ so we can apply \cref{thm_power_distance_dtm_inequality} to obtain the inequalities
		$$
		\frac{1}{\sqrt{2}}d_{X,\alpha, m}\leq d_{X,\alpha, m}^P \leq \sqrt{5}(d_{X,\alpha, m}+\alpha(n)).
		$$
	\end{ex}

	\todo[inline]{Can we hope for an additive interleaving instead of a multiplicative one?}

	\subsection{Approximating sublevel set homology by weighted complexes}
	\todo[inline]{Define weighted Čech/Rips complexes and give approximation results.}
	
	\subsection{Computing the distance to the disk measure}
	\todo[inline]{How to actually evaluate the function $d_{\mu_{X,\alpha}}$ on the points in $X$? See \autocite{li2011concise} for a derivation of formulas for the volume of sphere caps (needed to compute the volume of the intersections of hyperspheres).}

	\printbibliography
	

\end{document}